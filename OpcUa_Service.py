import asyncio
import logging
import sys
import time
import signal
import os
from logging.handlers import RotatingFileHandler
from typing import List, Any

# ç¬¬ä¸‰æ–¹åº“: pip install asyncua aiomysql loguru
import aiomysql
from asyncua import Client, ua
from asyncua.common.node import Node
from loguru import logger

# ================= é…ç½®åŒºåŸŸ (å»ºè®®ç”Ÿäº§ç¯å¢ƒæ”¾å…¥ .env æ–‡ä»¶) =================

# OPC UA æœåŠ¡ç«¯åœ°å€
OPC_URL = "opc.tcp://localhost:4840"

# éœ€è¦è®¢é˜…é‡‡é›†çš„ç‚¹ä½åˆ—è¡¨ (NodeID)
TARGET_NODES = [
    "ns=2;i=2",  # æ¸©åº¦
]

# æ•°æ®åº“è¿æ¥é…ç½®
DB_CONFIG = {
    'host': '127.0.0.1',
    'port': 3306,
    'user': 'root',
    'password': '123456',  # è¯·ä¿®æ”¹å¯†ç 
    'db': 'test01',
    'autocommit': True,
    'connect_timeout': 10
}

# æ€§èƒ½è°ƒä¼˜å‚æ•°
BATCH_SIZE = 500  # æ‰¹é‡å†™å…¥é˜ˆå€¼ï¼šæ”’å¤Ÿ500æ¡å†™ä¸€æ¬¡æ•°æ®åº“
FLUSH_INTERVAL = 5.0  # æ—¶é—´é˜ˆå€¼ï¼šæ¯3ç§’å¼ºåˆ¶å†™å…¥ä¸€æ¬¡ï¼ˆé˜²æ­¢æ•°æ®å°‘æ—¶ä¸å†™å…¥ï¼‰
QUEUE_MAX_SIZE = 50000  # å†…å­˜é˜Ÿåˆ—æœ€å¤§é•¿åº¦ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
LOG_DIR = "logs"  # æ—¥å¿—å­˜æ”¾ç›®å½•


# ================= 1. ç”Ÿäº§çº§æ—¥å¿—ç³»ç»Ÿè®¾ç½® =================

# def setup_logging():
#     """
#     é…ç½®æ—¥å¿—ç³»ç»Ÿï¼šåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
#     ä½¿ç”¨ RotatingFileHandler å®ç°æ—¥å¿—è½®è½¬ï¼Œé˜²æ­¢ç£ç›˜å†™æ»¡
#     """
#     if not os.path.exists(LOG_DIR):
#         os.makedirs(LOG_DIR)
#
#     # æ—¥å¿—æ ¼å¼: æ—¶é—´ - æ¨¡å—å - çº§åˆ« - å†…å®¹
#     log_format = logging.Formatter("%(asctime)s - %(name)s - [%(levelname)s] - %(message)s")
#
#     logger = logging.getLogger("IOT_Core")
#     logger.setLevel(logging.INFO)
#
#     # 1. æ§åˆ¶å°å¤„ç†å™¨
#     stream_handler = logging.StreamHandler(sys.stdout)
#     stream_handler.setFormatter(log_format)
#     logger.addHandler(stream_handler)
#
#     # 2. æ–‡ä»¶å¤„ç†å™¨ (æ—¥å¿—è½®è½¬)
#     # maxBytes=10MB: å•ä¸ªæ—¥å¿—æœ€å¤§10MB
#     # backupCount=5: ä¿ç•™æœ€è¿‘5ä¸ªæ—¥å¿—æ–‡ä»¶
#     file_handler = RotatingFileHandler(
#         filename=os.path.join(LOG_DIR, "service.log"),
#         maxBytes=10 * 1024 * 1024,
#         backupCount=5,
#         encoding='utf-8'
#     )
#     file_handler.setFormatter(log_format)
#     logger.addHandler(file_handler)
#
#     return logger
#
#
# logger = setup_logging()
# ================= 1. æ—¥å¿—åˆå§‹åŒ–ä¸é…ç½® =================

def setup_iot_logging():
    LOG_DIR = "logs"
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

    logger.remove()

    # A. æ§åˆ¶å°
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO",
        enqueue=True,
        colorize=True
    )

    # B. ä¸»æœåŠ¡æ—¥å¿— (æŒ‰å¤©æ»šåŠ¨ + å‹ç¼©)
    logger.add(
        os.path.join(LOG_DIR, "iot_service_{time:YYYY-MM-DD}.log"),
        rotation="00:00",
        retention="30 days",
        compression="zip",
        format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
        level="INFO",
        enqueue=True,
        encoding="utf-8"
    )

    # C. é”™è¯¯æ—¥å¿—ç‹¬ç«‹å¤‡ä»½ (ä¿®æ­£ç‚¹ï¼šretention=10)
    logger.add(
        os.path.join(LOG_DIR, "error_critical.log"),
        level="ERROR",
        rotation="10 MB",
        retention=10,  # ä¿ç•™æœ€è¿‘10ä¸ªæ–‡ä»¶
        enqueue=True
    )


setup_iot_logging()


# ================= 2. æ•°æ®åº“å†™å…¥æœåŠ¡ (æ¶ˆè´¹è€…) =================

class DatabaseService:
    def __init__(self, queue: asyncio.Queue):
        self.queue = queue
        self.pool = None
        self._running = True

    async def _init_pool(self):
        """å»ºç«‹æˆ–é‡å»ºæ•°æ®åº“è¿æ¥æ±  (ä¿æŒä¸å˜ï¼Œå¾ˆç¨³)"""
        while self._running:
            try:
                if self.pool:
                    self.pool.close()
                    await self.pool.wait_closed()
                self.pool = await aiomysql.create_pool(**DB_CONFIG, minsize=1, maxsize=10)
                logger.info(">>> æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
                return True
            except Exception as e:
                logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}ï¼Œ5ç§’åé‡è¯•...")
                await asyncio.sleep(5)
        return False

    async def flush_data(self, buffer: List[tuple]) -> bool:
        """çº¯ç²¹æ‰§è¡Œå†™å…¥ï¼Œä¸æˆåŠŸåˆ™è¿”å› False"""
        if not buffer or not self.pool:
            return False

        sql = "INSERT INTO iot_sensor_data (node_id, value, quality, source_time) VALUES (%s, %s, %s, %s)"
        try:
            async with self.pool.acquire() as conn:
                async with conn.cursor() as cur:
                    await cur.executemany(sql, buffer)
                    logger.info(f"æˆåŠŸå­˜å…¥ {len(buffer)} æ¡æ•°æ®")
                    return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“å†™å…¥æŠ¥é”™: {e}")
            return False

    async def run(self):
        """æ¶ˆè´¹è€…ä¸»å¾ªç¯"""
        await self._init_pool()
        buffer = []
        last_flush_time = time.time()
        try:
            while self._running:
                try:
                    # 1. å°è¯•ä»é˜Ÿåˆ—å–æ•°æ®
                    try:
                        item = await asyncio.wait_for(self.queue.get(), timeout=0.5)
                        buffer.append(item)
                    except asyncio.TimeoutError:
                        pass

                        # 2. æ£€æŸ¥è§¦å‘æ¡ä»¶
                    current_time = time.time()
                    if buffer and (len(buffer) >= BATCH_SIZE or (current_time - last_flush_time >= FLUSH_INTERVAL)):
                        # å°è¯•å†™å…¥
                        if await self.flush_data(buffer):
                            # æˆåŠŸæ‰æ¸…ç©º
                            for _ in range(len(buffer)): self.queue.task_done()
                            buffer = []
                            last_flush_time = current_time
                        else:
                            # å¤±è´¥åˆ™ä¸æ¸…é™¤ bufferï¼Œè§¦å‘è¿æ¥æ± é‡å»ºï¼Œè¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯é‡è¯•
                            logger.warning("æ•°æ®æš‚å­˜ç¼“å†²åŒºï¼Œæ­£åœ¨å°è¯•æ¢å¤è¿æ¥æ± ...")
                            await self._init_pool()
                            await asyncio.sleep(2)

                except asyncio.CancelledError:
                    # ç‰¹åˆ«å¤„ç†ä»»åŠ¡å–æ¶ˆä¿¡å·ï¼Œç¡®ä¿å®ƒèƒ½æŠ›å‡ºä»¥ä¾¿è¿›å…¥ finally
                    raise
                except Exception as e:
                    logger.error(f"DatabaseService æ„å¤–é”™è¯¯: {e}")
                    await asyncio.sleep(1)

        finally:
            # === åªè¦ run ç»“æŸï¼Œæ— è®ºæ˜¯æ­£å¸¸åœæ­¢è¿˜æ˜¯æŠ¥é”™ï¼Œéƒ½ä¼šæ‰§è¡Œè¿™é‡Œ ===
            logger.info("æ­£åœ¨æ‰§è¡Œ DatabaseService æ”¶å°¾æ¸…ç†...")

            # 1. å°è¯•åˆ·å†™ç¼“å†²åŒºå‰©ä½™æ•°æ®
            if buffer:
                logger.warning(f"æœåŠ¡åœæ­¢ï¼Œæ­£åœ¨åˆ·å†™å‰©ä½™ {len(buffer)} æ¡æ•°æ®...")
                # æ³¨æ„ï¼šå¦‚æœæ­¤æ—¶æ•°æ®åº“æœ¬æ¥å°±æ˜¯æ–­å¼€çš„ï¼Œè¿™é‡Œå¯èƒ½ä¼šå†æ¬¡å¤±è´¥
                # å·¥ä¸šçº§åº”ç”¨å¯ä»¥è€ƒè™‘åœ¨è¿™é‡Œå°† buffer å†™å…¥æœ¬åœ°æ–‡æœ¬æ–‡ä»¶
                await self.flush_data(buffer)

            # 2. å®‰å…¨å…³é—­è¿æ¥æ± 
            if self.pool:
                logger.info("æ­£åœ¨å…³é—­æ•°æ®åº“è¿æ¥æ± ...")
                self.pool.close()
                await self.pool.wait_closed()
                logger.info("æ•°æ®åº“è¿æ¥æ± å·²å½»åº•å…³é—­")

    def stop(self):
        self._running = False


# ================= 3. OPC UA è®¢é˜…å¤„ç† (ç”Ÿäº§è€…) =================

class SubscriptionHandler:
    """
    OPC UA è®¢é˜…å›è°ƒç±»
    æ³¨æ„: è¿™é‡Œçš„ä»£ç è¿è¡Œåœ¨ asyncua çš„å›è°ƒçº¿ç¨‹ä¸­ï¼Œå¿…é¡»éå¸¸å¿«ï¼Œä¸èƒ½é˜»å¡
    """

    def __init__(self, queue: asyncio.Queue, loop: asyncio.AbstractEventLoop):
        self.queue = queue
        self.loop = loop

    def datachange_notification(self, node: Node, val: Any, data):
        logger.info(f"æ”¶åˆ°åŸå§‹ä¿¡å·: {node.nodeid.to_string()} = {val}")
        """
        å½“ PLC ç‚¹ä½æ•°æ®å˜åŒ–æ—¶ï¼Œè‡ªåŠ¨è§¦å‘æ­¤å‡½æ•°
        """
        try:
            node_id = node.nodeid.to_string()

            # è·å–æ•°æ®æºæ—¶é—´æˆ³ (SourceTimestamp)ï¼Œè¿™æ˜¯æ•°æ®äº§ç”Ÿçš„çœŸå®æ—¶é—´
            source_ts = data.monitored_item.Value.SourceTimestamp
            # è·å–è´¨é‡ä»£ç 
            quality = str(data.monitored_item.Value.StatusCode)

            # å¦‚æœæ˜¯ datetime å¯¹è±¡ï¼Œç¡®ä¿å®ƒæ˜¯ UTC æˆ–è€…æœ¬åœ°æ—¶é—´ï¼Œè¿™é‡Œç›´æ¥å­˜å…¥
            # è¿™é‡Œçš„ val éœ€è¦è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œä¿è¯å…¼å®¹æ€§
            payload = (node_id, str(val), quality, source_ts)

            # put_nowait æ˜¯éé˜»å¡çš„
            # å¦‚æœé˜Ÿåˆ—æ»¡äº† (è¶…è¿‡ QUEUE_MAX_SIZE)ï¼Œä¼šæŠ›å‡º QueueFull å¼‚å¸¸
            # self.queue.put_nowait(payload)

            # ã€è±†åŒ…è¡¥ä¸ã€‘ï¼šçº¿ç¨‹å®‰å…¨åœ°å°†æ•°æ®æŠ•é€’å› asyncio äº‹ä»¶å¾ªç¯
            def put_into_queue():
                try:
                    self.queue.put_nowait(payload)
                except asyncio.QueueFull:
                    logger.warning("è­¦å‘Š: å†…å­˜é˜Ÿåˆ—å·²æ»¡ï¼æ•°æ®åº“å†™å…¥é€Ÿåº¦è·Ÿä¸ä¸Šé‡‡é›†é€Ÿåº¦ï¼Œæ­£åœ¨ä¸¢å¼ƒæ•°æ®ï¼")

            self.loop.call_soon_threadsafe(put_into_queue)

        except Exception as e:
            logger.error(f"å›è°ƒå¤„ç†å¼‚å¸¸: {e}")

    def status_change_notification(self, status):
        """
        å¤„ç†è®¢é˜…çŠ¶æ€å˜æ›´ï¼ˆå¦‚è¿æ¥ä¸­æ–­ã€Sessionå¤±æ•ˆç­‰ï¼‰
        ä¸å†æŒ‡å®šå‚æ•°ç±»å‹ï¼Œé˜²æ­¢ç‰ˆæœ¬ä¸å…¼å®¹
        """
        logger.warning(f"OPC UA è®¢é˜…çŠ¶æ€å˜æ›´: {status}")

    def event_notification(self, event):
        """
        å¤„ç†äº‹ä»¶é€šçŸ¥ï¼ˆå¦‚æŠ¥è­¦ï¼‰
        ä¸å†æŒ‡å®š ua.EventNotificationElementï¼Œé˜²æ­¢ AttributeError
        """
        logger.info(f"æ”¶åˆ° OPC UA äº‹ä»¶é€šçŸ¥: {event}")


# ================= 4. OPC UA å®¢æˆ·ç«¯ä¸»æœåŠ¡ =================

class OpcUaService:
    def __init__(self, queue: asyncio.Queue, loop: asyncio.AbstractEventLoop):
        self.queue = queue
        self.loop = loop
        self.client = None
        self._running = True

    async def run(self):
        """å®¢æˆ·ç«¯ä¸»å¾ªç¯ (åŒ…å«æ–­çº¿é‡è¿)"""
        logger.info(f"æ­£åœ¨å¯åŠ¨ OPC UA é‡‡é›†æœåŠ¡ï¼Œç›®æ ‡: {OPC_URL}")

        while self._running:
            self.client = None  # ç¡®ä¿æ¯æ¬¡å¾ªç¯å¼€å§‹å‰å¼•ç”¨æ˜¯å¹²å‡€çš„
            try:
                self.client = Client(url=OPC_URL)
                # è®¾ç½®è¿æ¥è¶…æ—¶ï¼Œé˜²æ­¢ç½‘ç»œæ­»æ‰æ—¶ç¨‹åºæ°¸ä¹…å¡æ­»åœ¨ connect()
                self.client.connect_timeout = 10
                # ç”Ÿäº§ç¯å¢ƒå®‰å…¨è®¾ç½® (å¦‚éœ€è´¦å·å¯†ç è¯·å–æ¶ˆæ³¨é‡Š)
                # self.client.set_user("admin")
                # self.client.set_password("123456")

                async with self.client:
                    logger.info("å·²è¿æ¥è‡³ OPC UA Server")

                    # 1. æ³¨å†Œ Namespace (å¯é€‰ï¼Œéƒ¨åˆ† PLC éœ€è¦)
                    # ns = await self.client.get_namespace_index(uri)

                    # 2. å»ºç«‹è®¢é˜…
                    handler = SubscriptionHandler(self.queue, self.loop)
                    # 500ms æ‰«æä¸€æ¬¡å˜åŒ–ï¼Œå¦‚æœè¿™é‡Œè®¾å¤ªå¿«ï¼ŒPLCè´Ÿè½½ä¼šå˜é«˜
                    sub = await self.client.create_subscription(500, handler)

                    # 3. è·å–ç‚¹ä½èŠ‚ç‚¹å¯¹è±¡
                    nodes = []
                    for node_str in TARGET_NODES:
                        try:
                            n = self.client.get_node(node_str)
                            nodes.append(n)
                        except Exception as e:
                            logger.error(f"æ— æ•ˆçš„ç‚¹ä½ ID: {node_str} - {e}")

                    if not nodes:
                        logger.error("æ²¡æœ‰æœ‰æ•ˆçš„ç‚¹ä½ï¼Œç­‰å¾…é‡è¯•...")
                        await asyncio.sleep(5)
                        continue

                    # 4. è®¢é˜…æ•°æ®å˜åŒ–
                    await sub.subscribe_data_change(nodes)
                    logger.info(f"æˆåŠŸè®¢é˜… {len(nodes)} ä¸ªç‚¹ä½ï¼Œè¿›å…¥ç›‘å¬æ¨¡å¼...")

                    # --- æ ¸å¿ƒå¿ƒè·³ç›‘æ§ ---
                    while self._running:
                        try:
                            # 1. å°è¯•è¯»å–æœåŠ¡å™¨å½“å‰æ—¶é—´æˆ–çŠ¶æ€ï¼Œè¿™æ˜¯æœ€å®æ—¶çš„é“¾è·¯æ£€æµ‹
                            # await self.client.nodes.server_state.read_value()

                            # ä½¿ç”¨æ ‡å‡†å¼ºåˆ¶èŠ‚ç‚¹ i=2259 (Server_ServerStatus_CurrentTime)
                            # è¿™åœ¨ Siemens, Beckhoff, Omron ç­‰æ‰€æœ‰æ ‡å‡† PLC ä¸Šéƒ½å­˜åœ¨
                            server_time_node = self.client.get_node(ua.NodeId(ua.ObjectIds.Server_ServerStatus_CurrentTime))
                            await server_time_node.read_value()

                        except Exception as e:
                            # å¦‚æœè¿™é‡Œè¯»å¤±è´¥äº†ï¼Œè¯´æ˜ TCP è¿æ¥å·²ç»ä¸å¯ç”¨äº†
                            logger.error(f"å¿ƒè·³æ£€æµ‹å¤±è´¥ï¼Œè¿æ¥å¯èƒ½å·²æ–­å¼€: {e}")
                            break  # è·³å‡ºå†…å¾ªç¯ï¼Œè¿›å…¥ finally è¿›è¡Œæ¸…ç†å¹¶é‡è¿

                        await asyncio.sleep(5)  # æ¯ 5 ç§’å¿ƒè·³ä¸€æ¬¡

            except (OSError, asyncio.TimeoutError, ua.UaError) as e:
                logger.error(f"è¿æ¥æ–­å¼€æˆ–ç½‘ç»œé”™è¯¯: {e}")
            except Exception as e:
                logger.critical(f"ä¸¥é‡æœªçŸ¥é”™è¯¯: {e}", exc_info=True)
            finally:
                if self.client:
                    try:
                        logger.info("æ­£åœ¨å¼ºåˆ¶æ–­å¼€å¹¶æ¸…ç†æ®‹ç•™è¿æ¥èµ„æº...")
                        await self.client.disconnect()
                    except:
                        logger.info("æ–­ç½‘æƒ…å†µä¸‹ disconnect æŠ¥é”™æ˜¯æ­£å¸¸çš„...")
                        pass  # æ–­ç½‘æƒ…å†µä¸‹ disconnect æŠ¥é”™æ˜¯æ­£å¸¸çš„

                if self._running:
                    logger.warning("5 ç§’åå°è¯•é‡æ–°è¿æ¥...")
                    await asyncio.sleep(5)

        logger.info("OPC UA æœåŠ¡å¾ªç¯å·²ç»“æŸ")

    def stop(self):
        self._running = False


# ================= 4. é˜Ÿåˆ—ç›‘æ§ä»»åŠ¡ =================
async def monitor_queue_task(queue: asyncio.Queue, max_size: int):
    """
    ä¸“é—¨çš„ç›‘æ§ä»»åŠ¡ï¼Œä¸å½±å“ä¸šåŠ¡é€»è¾‘
    æ¯ 10 ç§’æ‰“å°ä¸€æ¬¡é˜Ÿåˆ—å †ç§¯æƒ…å†µ
    """
    while True:
        try:
            q_size = queue.qsize()
            if q_size > 0:
                usage_pct = (q_size / max_size) * 100
                # å¦‚æœè´Ÿè½½è¶…è¿‡ 80%ï¼Œç”¨ warning çº§åˆ«æé†’
                level = "WARNING" if usage_pct > 80 else "INFO"
                logger.log(level, f"ğŸ“Š é˜Ÿåˆ—å¥åº·ç›‘æ§: å½“å‰å †ç§¯ {q_size} æ¡ | è´Ÿè½½ç‡ {usage_pct:.2f}%")

            await asyncio.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
        except asyncio.CancelledError:
            break
        except Exception as e:
            logger.error(f"ç›‘æ§ä»»åŠ¡å¼‚å¸¸: {e}")
            await asyncio.sleep(10)


# ================= 5. ç¨‹åºå…¥å£ä¸ç”Ÿå‘½å‘¨æœŸç®¡ç† =================

async def main():
    loop = asyncio.get_running_loop()
    # 1. åˆ›å»ºå…±äº«é˜Ÿåˆ— (é™åˆ¶å¤§å°ä¸º5ä¸‡æ¡ï¼Œé˜²æ­¢å†…å­˜ç‚¸è£‚)
    # å‡è®¾ä¸€æ¡æ•°æ®å ç”¨ 1KBï¼Œ5ä¸‡æ¡çº¦å ç”¨ 50MB å†…å­˜ï¼Œéå¸¸å®‰å…¨
    data_queue = asyncio.Queue(maxsize=QUEUE_MAX_SIZE)

    # 2. å®ä¾‹åŒ–æœåŠ¡
    db_service = DatabaseService(data_queue)
    opc_service = OpcUaService(data_queue, loop)

    # 3. æ³¨å†Œä¿¡å·å¤„ç† (ç”¨äºä¼˜é›…é€€å‡º)
    #loop = asyncio.get_running_loop()
    stop_event = asyncio.Event()

    def signal_handler():
        logger.warning("æ¥æ”¶åˆ°åœæ­¢ä¿¡å· (SIGINT/SIGTERM)ï¼Œæ­£åœ¨å‡†å¤‡å®‰å…¨é€€å‡º...")
        opc_service.stop()
        # æ³¨æ„ï¼šè¿™é‡Œä¸ç«‹å³åœæ­¢ DB æœåŠ¡ï¼Œè¦è®©å®ƒæŠŠé˜Ÿåˆ—é‡Œçš„å†™å®Œ
        stop_event.set()

    # æ³¨å†Œ Ctrl+C
    for sig in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig, signal_handler)
        except NotImplementedError:
            # Windows ä¸‹å¯èƒ½ä¸æ”¯æŒ add_signal_handlerï¼Œè¿™åªæ˜¯ä¸€ä¸ªè­¦å‘Š
            pass

    # 4. å¯åŠ¨ä»»åŠ¡
    # ä½¿ç”¨ create_task å°†å®ƒä»¬æ”¾å…¥åå°è¿è¡Œ
    task_monitor = asyncio.create_task(monitor_queue_task(data_queue, QUEUE_MAX_SIZE))
    task_db = asyncio.create_task(db_service.run())
    task_opc = asyncio.create_task(opc_service.run())

    # 5. ç­‰å¾…åœæ­¢ä¿¡å·
    # åœ¨ Windows ä¸‹å¦‚æœä¸æ”¯æŒä¿¡å·ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦æ”¹æˆ loop.run_forever() çš„å˜ä½“
    try:
        # ä¸»çº¿ç¨‹åœ¨è¿™é‡ŒæŒ‚èµ·ï¼Œç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å·
        while not stop_event.is_set():
            await asyncio.sleep(1)
    except KeyboardInterrupt:
        # Windows å…¼å®¹å¤„ç†
        signal_handler()

    # 6. é€€å‡ºæµç¨‹
    logger.info("æ­£åœ¨ç­‰å¾…ä»»åŠ¡ç»“æŸ...")

    # é¦–å…ˆåœæ­¢æ•°æ®åº“æ¶ˆè´¹è€…çš„è¿è¡Œæ ‡å¿—ï¼Œè®©å®ƒå¤„ç†å®Œå‰©ä½™æ•°æ®åé€€å‡ºå¾ªç¯
    db_service.stop()

    # ç­‰å¾…æ•°æ®åº“ä»»åŠ¡å½»åº•å®Œæˆ (åŒ…æ‹¬æœ€åä¸€æ¬¡ Flush)
    await task_db

    task_monitor.cancel()
    # å–æ¶ˆ OPC ä»»åŠ¡ (å› ä¸º OPC ä»»åŠ¡é€šå¸¸åœ¨ sleepï¼Œå¯ä»¥ç›´æ¥ cancel)
    task_opc.cancel()

    logger.info("æœåŠ¡å·²å®‰å…¨å…³é—­ (All Services Stopped).")


if __name__ == "__main__":
    # Windows å¹³å°ä¸‹çš„ asyncio ç­–ç•¥ä¿®å¤
    if sys.platform.lower() == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass  # å·²ç»å¤„ç†è¿‡äº†ï¼Œè¿™é‡Œå¿½ç•¥
