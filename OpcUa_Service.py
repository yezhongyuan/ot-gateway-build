import asyncio
import datetime
import logging
import sys
import time
import signal
import os
from logging.handlers import RotatingFileHandler
from typing import List, Any
import uuid
import json

# ç¬¬ä¸‰æ–¹åº“: pip install asyncua aiomysql loguru
import aiomysql
from asyncua import Client, ua
from asyncua.common.node import Node
from loguru import logger

# å¯¼å…¥æˆ‘ä»¬æ–°åˆ›å»ºçš„å½’æ¡£å™¨ç±»
from file_archiver import DailyFileArchiver

# ================= é…ç½®åŒºåŸŸ (å»ºè®®ç”Ÿäº§ç¯å¢ƒæ”¾å…¥ .env æ–‡ä»¶) =================

# OPC UA æœåŠ¡ç«¯åœ°å€
OPC_URL = "opc.tcp://172.21.254.50:49320"
# OPC_URL = "opc.tcp://localhost:4840"

# æ•°æ®åº“è¿æ¥é…ç½®
# DB_CONFIG = {
#     'host': '127.0.0.1',
#     'port': 3306,
#     'user': 'root',
#     'password': '123456',  # è¯·ä¿®æ”¹å¯†ç 
#     'db': 'test01',
#     'autocommit': True,
#     'connect_timeout': 10
# }

DB_CONFIG = {
    'host': '172.21.30.150',
    'port': 3306,
    'user': 'root',
    'password': '1qaz@WSX',  # è¯·ä¿®æ”¹å¯†ç 
    'db': 'kpsnc_upom_mes',
    'autocommit': True,
    'connect_timeout': 10
}

# æ€§èƒ½è°ƒä¼˜å‚æ•°
BATCH_SIZE = 500  # æ‰¹é‡å†™å…¥é˜ˆå€¼ï¼šæ”’å¤Ÿ500æ¡å†™ä¸€æ¬¡æ•°æ®åº“
FLUSH_INTERVAL = 5.0  # æ—¶é—´é˜ˆå€¼ï¼šæ¯3ç§’å¼ºåˆ¶å†™å…¥ä¸€æ¬¡ï¼ˆé˜²æ­¢æ•°æ®å°‘æ—¶ä¸å†™å…¥ï¼‰
QUEUE_MAX_SIZE = 50000  # å†…å­˜é˜Ÿåˆ—æœ€å¤§é•¿åº¦ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
LOG_DIR = "logs"  # æ—¥å¿—å­˜æ”¾ç›®å½•


# ================= 1. æ—¥å¿—åˆå§‹åŒ–ä¸é…ç½® =================

def setup_iot_logging():
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

    logger.remove()

    # A. æ§åˆ¶å°
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> "
               "| <level>{level: <8}</level> "
               "| <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> "
               "| <level>{message}</level>",
        level="DEBUG",
        enqueue=True,
        colorize=True
    )

    # B. ä¸»æœåŠ¡æ—¥å¿— (æŒ‰å¤©æ»šåŠ¨ + å‹ç¼©)
    logger.add(
        os.path.join(LOG_DIR, "iot_service_{time:YYYY-MM-DD}.log"),
        rotation="00:00",
        retention="30 days",
        compression="zip",
        format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
        level="INFO",
        enqueue=True,
        encoding="utf-8"
    )

    # C. é”™è¯¯æ—¥å¿—ç‹¬ç«‹å¤‡ä»½ (ä¿®æ­£ç‚¹ï¼šretention=10)
    logger.add(
        os.path.join(LOG_DIR, "error_critical.log"),
        level="ERROR",
        rotation="10 MB",
        retention=10,  # ä¿ç•™æœ€è¿‘10ä¸ªæ–‡ä»¶
        enqueue=True
    )


setup_iot_logging()


def load_target_nodes_config(config_path: str = "nodes_config.json") -> dict:
    if getattr(sys, 'frozen', False):
        config_path = os.path.join(os.path.dirname(sys.executable), "nodes_config.json")
    """ä»JSONæ–‡ä»¶åŠ è½½ç›®æ ‡èŠ‚ç‚¹é…ç½®"""
    if not os.path.exists(config_path):
        # ä½¿ç”¨ logger.error æ›¿æ¢ logging.error
        logger.error(f"ç›®æ ‡èŠ‚ç‚¹é…ç½®æ–‡ä»¶ '{config_path}' æœªæ‰¾åˆ°ï¼ç¨‹åºå°†æ— æ³•é‡‡é›†ä»»ä½•æ•°æ®ã€‚")
        return {}

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        # ä½¿ç”¨ logger.error æ›¿æ¢ logging.error
        logger.error(f"è§£æé…ç½®æ–‡ä»¶ '{config_path}' æ—¶å‡ºé”™ (JSONæ ¼å¼é”™è¯¯): {e}")
        return {}
    except Exception as e:
        # ä½¿ç”¨ logger.error æ›¿æ¢ logging.error
        logger.error(f"è¯»å–é…ç½®æ–‡ä»¶ '{config_path}' æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return {}


def log_config_summary(nodes_config: dict):
    """
    æ‰“å°åŠ è½½çš„è®¾å¤‡å’Œç‚¹ä½é…ç½®æ‘˜è¦ã€‚
    """
    if not nodes_config:
        logger.warning("æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•è®¾å¤‡é…ç½®ï¼Œå°†ä¸æ‰“å°é…ç½®æ‘˜è¦ã€‚")
        return

    logger.info("=" * 60)
    logger.info("         è®¾å¤‡ä¸ç‚¹ä½é…ç½®åŠ è½½æ‘˜è¦")
    logger.info("=" * 60)

    for device_name, device_info in nodes_config.items():
        # æ‰“å°è®¾å¤‡åç§°
        logger.info(f"  è®¾å¤‡åç§°: {device_name}")

        # æ‰“å°è§¦å‘ç‚¹ä½
        trigger_node = device_info.get("trigger")
        if trigger_node:
            logger.info(f"    â””â”€ è§¦å‘ç‚¹ä½: {trigger_node}")
        else:
            logger.warning(f"    â””â”€ è­¦å‘Š: è®¾å¤‡ '{device_name}' æœªé…ç½®è§¦å‘ç‚¹ä½ï¼")

        # æ‰“å°å…³è”çš„é‡‡é›†ç‚¹ä½
        items = device_info.get("items", [])
        if items:
            logger.info(f"    â””â”€ é‡‡é›†ç‚¹ä½ ({len(items)}ä¸ª):")
            for i, item_node in enumerate(items, 1):
                logger.info(f"        [{i}] {item_node}")
        else:
            logger.warning(f"    â””â”€ è­¦å‘Š: è®¾å¤‡ '{device_name}' æœªé…ç½®ä»»ä½•é‡‡é›†ç‚¹ä½ï¼")

        logger.info("-" * 40)  # æ‰“å°åˆ†éš”çº¿ï¼Œä½¿è¾“å‡ºæ›´æ¸…æ™°

    logger.info("=" * 60)
    logger.info(f"é…ç½®æ‘˜è¦æ‰“å°å®Œæ¯•ï¼Œå…±åŠ è½½ {len(nodes_config)} ä¸ªè®¾å¤‡ã€‚")
    logger.info("=" * 60)


# --- åœ¨ç¨‹åºå¯åŠ¨æ—¶åŠ è½½é…ç½® ---
TARGET_NODES = load_target_nodes_config()
TRIGGER_TO_DEVICE = {v["trigger"]: k for k, v in TARGET_NODES.items()}

# --- åœ¨åŠ è½½é…ç½®åæ‰“å°è¯»å–ä¿¡æ¯ ---
log_config_summary(TARGET_NODES)


# ================= 2. æ•°æ®åº“å†™å…¥æœåŠ¡ (æ¶ˆè´¹è€…) =================

class DatabaseService:
    def __init__(self, queue: asyncio.Queue, archiver: DailyFileArchiver):
        self.queue = queue
        self.pool = None
        self._running = True
        self.archiver = archiver  # ä¿å­˜å½’æ¡£å™¨å®ä¾‹

    async def _init_pool(self):
        """å»ºç«‹æˆ–é‡å»ºæ•°æ®åº“è¿æ¥æ±  (ä¿æŒä¸å˜ï¼Œå¾ˆç¨³)"""
        while self._running:
            try:
                if self.pool:
                    self.pool.close()
                    await self.pool.wait_closed()
                self.pool = await aiomysql.create_pool(**DB_CONFIG, minsize=1, maxsize=10)
                logger.info(">>> æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
                return True
            except Exception as e:
                logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}ï¼Œ5ç§’åé‡è¯•...")
                await asyncio.sleep(5)
        return False

    async def flush_data(self, buffer: List[tuple]) -> bool:
        """çº¯ç²¹æ‰§è¡Œå†™å…¥ï¼Œä¸æˆåŠŸåˆ™è¿”å› False"""
        if not buffer or not self.pool:
            return False

        # === æ–°å¢ï¼šæ‰“å°æ¯æ¡è®°å½•çš„ç®€è¦ä¿¡æ¯ ===
        for i, record in enumerate(buffer):
            rfid, node_id, value, quality, source_time, trace_id = record
            logger.debug(
                f"å‡†å¤‡å†™å…¥ [{i + 1}/{len(buffer)}] | "
                f"è®¾å¤‡: {node_id} | "
                f"RFID: {rfid} | "
                f"å€¼: {value} | "
                f"æ—¶é—´: {source_time} | "
                f"Trace: {trace_id}"
            )

        sql = "INSERT INTO iot_sensor_data (rfid, node_id, value, quality, source_time, trace_id) VALUES (%s, %s, %s, %s, %s, %s)"
        buffer_to_write = buffer.copy()
        try:
            async with self.pool.acquire() as conn:
                async with conn.cursor() as cur:
                    await cur.executemany(sql, buffer)
                    logger.info(f"æˆåŠŸå­˜å…¥ {len(buffer)} æ¡æ•°æ®")

            # 2. æ•°æ®åº“å†™å…¥æˆåŠŸåï¼Œç«‹å³åœ¨åå°å‘èµ·ä¸€ä¸ªCSVå†™å…¥ä»»åŠ¡ (éé˜»å¡)
            # è¿™æ ·æ–‡ä»¶å†™å…¥ä¸ä¼šå½±å“ flush_data çš„è¿”å›æ—¶é—´å’Œè¿”å›å€¼
            asyncio.create_task(self._write_to_csv(buffer_to_write))
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“å†™å…¥æŠ¥é”™: {e}")
            # å³ä½¿æ•°æ®åº“å†™å…¥å¤±è´¥ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©å¤‡ä»½æ•°æ®åˆ°CSVï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜
            logger.warning(f"æ•°æ®åº“å†™å…¥å¤±è´¥ï¼Œå°è¯•å°† {len(buffer_to_write)} æ¡æ•°æ®å¤‡ä»½åˆ°CSV...")
            asyncio.create_task(self._write_to_csv(buffer_to_write))
            return False

    async def _write_to_csv(self, buffer: List[tuple]):
        """ä¸€ä¸ªä¸“é—¨ç”¨äºå¼‚æ­¥å†™å…¥CSVçš„è¾…åŠ©æ–¹æ³•"""
        try:
            self.archiver.write_rows(buffer)
        except Exception as e:
            # è®°å½•æ–‡ä»¶å†™å…¥çš„é”™è¯¯ï¼Œä½†ä¸å½±å“ä¸»æµç¨‹
            logger.error(f"åå°CSVå†™å…¥ä»»åŠ¡å‘ç”Ÿé”™è¯¯: {e}")

    async def run(self):
        """æ¶ˆè´¹è€…ä¸»å¾ªç¯"""
        await self._init_pool()
        buffer = []
        last_flush_time = time.time()
        try:
            while self._running:
                try:
                    # 1. å°è¯•ä»é˜Ÿåˆ—å–æ•°æ®
                    try:
                        item = await asyncio.wait_for(self.queue.get(), timeout=0.5)
                        buffer.append(item)
                    except asyncio.TimeoutError:
                        pass

                        # 2. æ£€æŸ¥è§¦å‘æ¡ä»¶
                    current_time = time.time()
                    if buffer and (len(buffer) >= BATCH_SIZE or (current_time - last_flush_time >= FLUSH_INTERVAL)):
                        # å°è¯•å†™å…¥
                        if await self.flush_data(buffer):
                            # æˆåŠŸæ‰æ¸…ç©º
                            for _ in range(len(buffer)): self.queue.task_done()
                            buffer = []
                            last_flush_time = current_time
                        else:
                            # å¤±è´¥åˆ™ä¸æ¸…é™¤ bufferï¼Œè§¦å‘è¿æ¥æ± é‡å»ºï¼Œè¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯é‡è¯•
                            logger.warning("æ•°æ®æš‚å­˜ç¼“å†²åŒºï¼Œæ­£åœ¨å°è¯•æ¢å¤è¿æ¥æ± ...")
                            await self._init_pool()
                            await asyncio.sleep(2)

                except asyncio.CancelledError:
                    # ç‰¹åˆ«å¤„ç†ä»»åŠ¡å–æ¶ˆä¿¡å·ï¼Œç¡®ä¿å®ƒèƒ½æŠ›å‡ºä»¥ä¾¿è¿›å…¥ finally
                    raise
                except Exception as e:
                    logger.error(f"DatabaseService æ„å¤–é”™è¯¯: {e}")
                    await asyncio.sleep(1)

        finally:
            # === åªè¦ run ç»“æŸï¼Œæ— è®ºæ˜¯æ­£å¸¸åœæ­¢è¿˜æ˜¯æŠ¥é”™ï¼Œéƒ½ä¼šæ‰§è¡Œè¿™é‡Œ ===
            logger.info("æ­£åœ¨æ‰§è¡Œ DatabaseService æ”¶å°¾æ¸…ç†...")

            # 1. å°è¯•åˆ·å†™ç¼“å†²åŒºå‰©ä½™æ•°æ®
            if buffer:
                logger.warning(f"æœåŠ¡åœæ­¢ï¼Œæ­£åœ¨åˆ·å†™å‰©ä½™ {len(buffer)} æ¡æ•°æ®...")
                # æ³¨æ„ï¼šå¦‚æœæ­¤æ—¶æ•°æ®åº“æœ¬æ¥å°±æ˜¯æ–­å¼€çš„ï¼Œè¿™é‡Œå¯èƒ½ä¼šå†æ¬¡å¤±è´¥
                # å·¥ä¸šçº§åº”ç”¨å¯ä»¥è€ƒè™‘åœ¨è¿™é‡Œå°† buffer å†™å…¥æœ¬åœ°æ–‡æœ¬æ–‡ä»¶
                await self.flush_data(buffer)

            # 2. å®‰å…¨å…³é—­è¿æ¥æ± 
            if self.pool:
                logger.info("æ­£åœ¨å…³é—­æ•°æ®åº“è¿æ¥æ± ...")
                self.pool.close()
                await self.pool.wait_closed()
                logger.info("æ•°æ®åº“è¿æ¥æ± å·²å½»åº•å…³é—­")

    def stop(self):
        self._running = False


# ================= 3. OPC UA è®¢é˜…å¤„ç† (ç”Ÿäº§è€…) =================

class SubscriptionHandler:
    """
    OPC UA è®¢é˜…å›è°ƒç±»
    æ³¨æ„: è¿™é‡Œçš„ä»£ç è¿è¡Œåœ¨ asyncua çš„å›è°ƒçº¿ç¨‹ä¸­ï¼Œå¿…é¡»éå¸¸å¿«ï¼Œä¸èƒ½é˜»å¡
    """

    def __init__(self, queue: asyncio.Queue, client, loop: asyncio.AbstractEventLoop):
        self.queue = queue
        self.loop = loop
        self.client = client
        self.last_values = {}  # è®°å½•ä¸Šæ¬¡ä¿¡å·çŠ¶æ€

    def datachange_notification(self, node: Node, val: Any, data):

        # === æ–°å¢ï¼šä¸ºæœ¬æ¬¡è§¦å‘ç”Ÿæˆå”¯ä¸€ID ===
        trace_id = str(uuid.uuid4())  # å–å‰8ä½è¶³å¤ŸåŒºåˆ†ï¼Œå¦‚ "a1b2c3d4"

        # === æ–°å¢ï¼šæ‰“å°åŸå§‹ Variant ä¿¡æ¯ ===
        variant = data.monitored_item.Value
        logger.debug(f"[{trace_id}] åŸå§‹ä¿¡å· Variant: Value={variant.Value!r}, "f"StatusCode={variant.StatusCode}")

        """
        å½“ PLC ç‚¹ä½æ•°æ®å˜åŒ–æ—¶ï¼Œè‡ªåŠ¨è§¦å‘æ­¤å‡½æ•°
        """
        try:

            node_id = node.nodeid.to_string()
            prev_val = self.last_values.get(node_id)
            self.last_values[node_id] = val

            device_name = TRIGGER_TO_DEVICE.get(node_id)
            if not device_name:
                return

            triggered = False

            logger.info(f"[{trace_id}] ğŸ”” ä¿¡å·å˜åŒ– | è®¾å¤‡: {device_name} | ç‚¹ä½: {node.nodeid.to_string()} | æ–°å€¼: {val!r} | æ—§å€¼: {prev_val!r}")

            if isinstance(val, bool):
                # === å¸ƒå°”æ¨¡å¼ï¼šä¸Šå‡æ²¿è§¦å‘ ===
                if val is True and (prev_val is False or prev_val is None):
                    triggered = True

            elif isinstance(val, str) or val is None:
                # === å­—ç¬¦ä¸²æ¨¡å¼ï¼šå•ä»¶ç å˜æ›´è§¦å‘ ===
                current_clean = (val or "").strip()  # None â†’ "", ç„¶å strip
                prev_clean = prev_val.strip() if isinstance(prev_val, str) else ""

                # === æ–°å¢ï¼šå§‹ç»ˆæ‰“å°åŸå§‹å€¼å’Œæ¸…æ´—åå€¼ï¼ˆç”¨äºæ’æŸ¥ï¼‰===
                logger.debug(
                    f"[{trace_id}] å­—ç¬¦ä¸²ç‚¹ä½å˜æ›´ | èŠ‚ç‚¹: {node_id} | "
                    f"åŸå§‹æ–°å€¼: {val!r} â†’ æ¸…æ´—å: {current_clean!r} | "
                    f"åŸå§‹æ—§å€¼: {prev_val!r} â†’ æ¸…æ´—å: {prev_clean!r}"
                )
                # è§¦å‘æ¡ä»¶ï¼šå½“å‰éç©º ä¸” ä¸ä¸Šæ¬¡ä¸åŒ
                if current_clean != "" and current_clean != prev_clean:
                    triggered = True

            else:
                # å¯é€‰ï¼šå¿½ç•¥å…¶ä»–ç±»å‹ï¼Œæˆ–æŒ‰éœ€æ‰©å±•ï¼ˆå¦‚ int çŠ¶æ€ç ï¼‰
                logger.error(f"å¿½ç•¥é bool/str ç±»å‹ä¿¡å·: {type(val).__name__} = {val!r}")
                return

            if triggered:
                logger.info(f"[{trace_id}] ğŸ”” è§¦å‘é˜Ÿåˆ—äº‹ä»¶ | è®¾å¤‡: {device_name} | ç‚¹ä½: {node.nodeid.to_string()} | " f"æ–°å€¼: {val!r} | æ—§å€¼: {prev_val!r}")
                # è·¨çº¿ç¨‹æ´¾å‘å¼‚æ­¥ä»»åŠ¡
                asyncio.run_coroutine_threadsafe(self.read_associated_data(device_name, val, trace_id), self.loop)

        except Exception as e:
            logger.error(f"å›è°ƒå¤„ç†å¼‚å¸¸: {e}")

    async def read_associated_data(self, device_name, rfid, trace_id):

        try:
            config = TARGET_NODES.get(device_name)
            if not config: return

            nodes = [self.client.get_node(nid) for nid in config["items"]]

            # æ‰¹é‡è¯»å– + è¶…æ—¶ä¿æŠ¤
            values = await asyncio.wait_for(self.client.read_values(nodes), timeout=3.0)

            # 3. ã€æ ¸å¿ƒä¿®æ”¹ã€‘ï¼šæå–ç‚¹ä½åå­—å¹¶æ„å»ºå­—å…¸
            # æ¯”å¦‚ä» "ns=2;s=DeviceA.Temp" ä¸­æå–å‡º "Temp"
            data_dict = {}
            for i, node_id in enumerate(config["items"]):
                # æŠ€å·§ï¼šå–ç‚¹ä½å­—ç¬¦ä¸²æœ€åä¸€éƒ¨åˆ†ä½œä¸º Key
                key = node_id.split('.')[-1]
                val = values[i]
                # è½¬æ¢æ•°å€¼ç±»å‹ï¼šå¦‚æœæ˜¯ float åˆ™ä¿ç•™ä¸¤ä½å°æ•°
                data_dict[key] = round(val, 2) if isinstance(val, (float, int)) else val

            # 4. è½¬æ¢æˆæ ‡å‡†çš„ JSON å­—ç¬¦ä¸²
            try:
                json_payload = json.dumps(data_dict, ensure_ascii=False)
            except Exception as e:
                logger.error(f"[{trace_id}] JSON åºåˆ—åŒ–å¤±è´¥: {e}, åŸå§‹æ•°æ®: {data_dict}")
                return

            # 5. å…¥é˜Ÿ (æ ¼å¼: è®¾å¤‡å, JSONå†…å®¹, è´¨é‡, æ—¶é—´)
            payload = (
                rfid,
                device_name,
                json_payload,
                "Good",
                datetime.datetime.now(),
                trace_id
            )

            try:
                self.queue.put_nowait(payload)
                logger.info(f"[{trace_id}] âœ… {device_name} å®Œå·¥ä¿¡å·ï¼š{rfid} æ•°æ®å·²å…¥é˜Ÿ: {json_payload}")
            except asyncio.QueueFull:
                logger.warning("[{trace_id}] è­¦å‘Š: å†…å­˜é˜Ÿåˆ—å·²æ»¡ï¼æ•°æ®åº“å†™å…¥é€Ÿåº¦è·Ÿä¸ä¸Šé‡‡é›†é€Ÿåº¦ï¼Œæ­£åœ¨ä¸¢å¼ƒæ•°æ®ï¼")
        except asyncio.TimeoutError:
            logger.error(f"[{trace_id}] âŒ {device_name} è¯»å–è¶…æ—¶")
        except Exception as e:
            logger.error(f"[{trace_id}] è¯»å–ä»»åŠ¡å¼‚å¸¸: {e}")

    def status_change_notification(self, status):
        """
        å¤„ç†è®¢é˜…çŠ¶æ€å˜æ›´ï¼ˆå¦‚è¿æ¥ä¸­æ–­ã€Sessionå¤±æ•ˆç­‰ï¼‰
        ä¸å†æŒ‡å®šå‚æ•°ç±»å‹ï¼Œé˜²æ­¢ç‰ˆæœ¬ä¸å…¼å®¹
        """
        logger.warning(f"OPC UA è®¢é˜…çŠ¶æ€å˜æ›´: {status}")

    def event_notification(self, event):
        """
        å¤„ç†äº‹ä»¶é€šçŸ¥ï¼ˆå¦‚æŠ¥è­¦ï¼‰
        ä¸å†æŒ‡å®š ua.EventNotificationElementï¼Œé˜²æ­¢ AttributeError
        """
        logger.info(f"æ”¶åˆ° OPC UA äº‹ä»¶é€šçŸ¥: {event}")


# ================= 4. OPC UA å®¢æˆ·ç«¯ä¸»æœåŠ¡ =================

class OpcUaService:
    def __init__(self, queue: asyncio.Queue, loop: asyncio.AbstractEventLoop):
        self.queue = queue
        self.loop = loop
        self.client = None
        self._running = True

    async def run(self):
        """å®¢æˆ·ç«¯ä¸»å¾ªç¯ (åŒ…å«æ–­çº¿é‡è¿)"""
        logger.info(f"æ­£åœ¨å¯åŠ¨ OPC UA é‡‡é›†æœåŠ¡ï¼Œç›®æ ‡: {OPC_URL}")

        while self._running:
            self.client = None  # ç¡®ä¿æ¯æ¬¡å¾ªç¯å¼€å§‹å‰å¼•ç”¨æ˜¯å¹²å‡€çš„
            try:
                self.client = Client(url=OPC_URL)
                # è®¾ç½®è¿æ¥è¶…æ—¶ï¼Œé˜²æ­¢ç½‘ç»œæ­»æ‰æ—¶ç¨‹åºæ°¸ä¹…å¡æ­»åœ¨ connect()
                self.client.connect_timeout = 10
                self.client.session_timeout = 60000  # æ˜¾å¼è®¾ä¸º 60 ç§’
                # ç”Ÿäº§ç¯å¢ƒå®‰å…¨è®¾ç½® (å¦‚éœ€è´¦å·å¯†ç è¯·å–æ¶ˆæ³¨é‡Š)
                # self.client.set_user("admin")
                # self.client.set_password("123456")

                async with self.client:
                    logger.info("å·²è¿æ¥è‡³ OPC UA Server")

                    # 1. æ³¨å†Œ Namespace (å¯é€‰ï¼Œéƒ¨åˆ† PLC éœ€è¦)
                    # ns = await self.client.get_namespace_index(uri)

                    # 1. æå–æ‰€æœ‰çš„ trigger èŠ‚ç‚¹è¿›è¡Œè®¢é˜…
                    trigger_nodes = [self.client.get_node(v["trigger"]) for v in TARGET_NODES.values()]

                    # 2. åˆ›å»ºè®¢é˜…
                    handler = SubscriptionHandler(self.queue, self.client, self.loop)
                    sub = await self.client.create_subscription(500, handler)

                    # 3. è®¢é˜…æ‰€æœ‰è§¦å‘ä¿¡å·
                    await sub.subscribe_data_change(trigger_nodes)
                    logger.info(f"ğŸ“¡ å·²è®¢é˜… {len(trigger_nodes)} ä¸ªè®¾å¤‡çš„è§¦å‘ä¿¡å·")

                    # --- æ ¸å¿ƒå¿ƒè·³ç›‘æ§ ---
                    while self._running:
                        try:
                            # 1. å°è¯•è¯»å–æœåŠ¡å™¨å½“å‰æ—¶é—´æˆ–çŠ¶æ€ï¼Œè¿™æ˜¯æœ€å®æ—¶çš„é“¾è·¯æ£€æµ‹
                            # await self.client.nodes.server_state.read_value()

                            # ä½¿ç”¨æ ‡å‡†å¼ºåˆ¶èŠ‚ç‚¹ i=2259 (Server_ServerStatus_CurrentTime)
                            # è¿™åœ¨ Siemens, Beckhoff, Omron ç­‰æ‰€æœ‰æ ‡å‡† PLC ä¸Šéƒ½å­˜åœ¨
                            server_time_node = self.client.get_node(
                                ua.NodeId(ua.ObjectIds.Server_ServerStatus_CurrentTime))
                            await server_time_node.read_value()

                        except Exception as e:
                            # å¦‚æœè¿™é‡Œè¯»å¤±è´¥äº†ï¼Œè¯´æ˜ TCP è¿æ¥å·²ç»ä¸å¯ç”¨äº†
                            logger.error(f"å¿ƒè·³æ£€æµ‹å¤±è´¥ï¼Œè¿æ¥å¯èƒ½å·²æ–­å¼€: {e}")
                            break  # è·³å‡ºå†…å¾ªç¯ï¼Œè¿›å…¥ finally è¿›è¡Œæ¸…ç†å¹¶é‡è¿

                        await asyncio.sleep(5)  # æ¯ 5 ç§’å¿ƒè·³ä¸€æ¬¡

            except (OSError, asyncio.TimeoutError, ua.UaError) as e:
                logger.error(f"è¿æ¥æ–­å¼€æˆ–ç½‘ç»œé”™è¯¯: {e}")
            except Exception as e:
                logger.critical(f"ä¸¥é‡æœªçŸ¥é”™è¯¯: {e}", exc_info=True)
            finally:
                if self.client:
                    try:
                        logger.info("æ­£åœ¨å¼ºåˆ¶æ–­å¼€å¹¶æ¸…ç†æ®‹ç•™è¿æ¥èµ„æº...")
                        await self.client.disconnect()
                    except:
                        logger.info("æ–­ç½‘æƒ…å†µä¸‹ disconnect æŠ¥é”™æ˜¯æ­£å¸¸çš„...")
                        pass  # æ–­ç½‘æƒ…å†µä¸‹ disconnect æŠ¥é”™æ˜¯æ­£å¸¸çš„

                if self._running:
                    logger.warning("5 ç§’åå°è¯•é‡æ–°è¿æ¥...")
                    await asyncio.sleep(5)

        logger.info("OPC UA æœåŠ¡å¾ªç¯å·²ç»“æŸ")

    def stop(self):
        self._running = False


# ================= 4. é˜Ÿåˆ—ç›‘æ§ä»»åŠ¡ =================
async def monitor_queue_task(queue: asyncio.Queue, max_size: int):
    """
    ä¸“é—¨çš„ç›‘æ§ä»»åŠ¡ï¼Œä¸å½±å“ä¸šåŠ¡é€»è¾‘
    æ¯ 10 ç§’æ‰“å°ä¸€æ¬¡é˜Ÿåˆ—å †ç§¯æƒ…å†µ
    """
    while True:
        try:
            q_size = queue.qsize()
            if q_size > 0:
                usage_pct = (q_size / max_size) * 100
                # å¦‚æœè´Ÿè½½è¶…è¿‡ 80%ï¼Œç”¨ warning çº§åˆ«æé†’
                level = "WARNING" if usage_pct > 80 else "INFO"
                logger.log(level, f"ğŸ“Š é˜Ÿåˆ—å¥åº·ç›‘æ§: å½“å‰å †ç§¯ {q_size} æ¡ | è´Ÿè½½ç‡ {usage_pct:.2f}%")

            await asyncio.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
        except asyncio.CancelledError:
            break
        except Exception as e:
            logger.error(f"ç›‘æ§ä»»åŠ¡å¼‚å¸¸: {e}")
            await asyncio.sleep(10)


# ================= 5. ç¨‹åºå…¥å£ä¸ç”Ÿå‘½å‘¨æœŸç®¡ç† =================

async def main():
    loop = asyncio.get_running_loop()
    # 1. åˆ›å»ºå…±äº«é˜Ÿåˆ— (é™åˆ¶å¤§å°ä¸º5ä¸‡æ¡ï¼Œé˜²æ­¢å†…å­˜ç‚¸è£‚)
    # å‡è®¾ä¸€æ¡æ•°æ®å ç”¨ 1KBï¼Œ5ä¸‡æ¡çº¦å ç”¨ 50MB å†…å­˜ï¼Œéå¸¸å®‰å…¨
    data_queue = asyncio.Queue(maxsize=QUEUE_MAX_SIZE)

    # --- å…³é”®ä¿®æ”¹ï¼šåœ¨è¿™é‡Œåˆ›å»º DailyFileArchiver å®ä¾‹ ---
    csv_headers = ['rfid', 'node_id', 'value', 'quality', 'source_time', 'trace_id']
    file_archiver = DailyFileArchiver(base_filename="iot_backup", headers=csv_headers)

    # 2. å®ä¾‹åŒ–æœåŠ¡
    db_service = DatabaseService(data_queue, file_archiver)
    opc_service = OpcUaService(data_queue, loop)

    # 3. æ³¨å†Œä¿¡å·å¤„ç† (ç”¨äºä¼˜é›…é€€å‡º)
    #loop = asyncio.get_running_loop()
    stop_event = asyncio.Event()

    def signal_handler():
        logger.warning("æ¥æ”¶åˆ°åœæ­¢ä¿¡å· (SIGINT/SIGTERM)ï¼Œæ­£åœ¨å‡†å¤‡å®‰å…¨é€€å‡º...")
        opc_service.stop()
        # æ³¨æ„ï¼šè¿™é‡Œä¸ç«‹å³åœæ­¢ DB æœåŠ¡ï¼Œè¦è®©å®ƒæŠŠé˜Ÿåˆ—é‡Œçš„å†™å®Œ
        stop_event.set()

    # æ³¨å†Œ Ctrl+C
    for sig in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(sig, signal_handler)
        except NotImplementedError:
            # Windows ä¸‹å¯èƒ½ä¸æ”¯æŒ add_signal_handlerï¼Œè¿™åªæ˜¯ä¸€ä¸ªè­¦å‘Š
            pass

    # 4. å¯åŠ¨ä»»åŠ¡ï¼Œä½¿ç”¨ create_task å°†å®ƒä»¬æ”¾å…¥åå°è¿è¡Œ
    task_monitor = asyncio.create_task(monitor_queue_task(data_queue, QUEUE_MAX_SIZE))
    task_db = asyncio.create_task(db_service.run())
    task_opc = asyncio.create_task(opc_service.run())

    # 5. ç­‰å¾…åœæ­¢ä¿¡å·
    # åœ¨ Windows ä¸‹å¦‚æœä¸æ”¯æŒä¿¡å·ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦æ”¹æˆ loop.run_forever() çš„å˜ä½“
    try:
        # ä¸»çº¿ç¨‹åœ¨è¿™é‡ŒæŒ‚èµ·ï¼Œç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å·
        while not stop_event.is_set():
            await asyncio.sleep(1)
    except KeyboardInterrupt:
        # Windows å…¼å®¹å¤„ç†
        signal_handler()

    # 6. é€€å‡ºæµç¨‹
    logger.info("æ­£åœ¨ç­‰å¾…ä»»åŠ¡ç»“æŸ...")

    # é¦–å…ˆåœæ­¢æ•°æ®åº“æ¶ˆè´¹è€…çš„è¿è¡Œæ ‡å¿—ï¼Œè®©å®ƒå¤„ç†å®Œå‰©ä½™æ•°æ®åé€€å‡ºå¾ªç¯
    db_service.stop()

    # ç­‰å¾…æ•°æ®åº“ä»»åŠ¡å½»åº•å®Œæˆ (åŒ…æ‹¬æœ€åä¸€æ¬¡ Flush)
    await task_db

    task_monitor.cancel()
    # å–æ¶ˆ OPC ä»»åŠ¡ (å› ä¸º OPC ä»»åŠ¡é€šå¸¸åœ¨ sleepï¼Œå¯ä»¥ç›´æ¥ cancel)
    task_opc.cancel()

    logger.info("æœåŠ¡å·²å®‰å…¨å…³é—­ (All Services Stopped).")


if __name__ == "__main__":
    # Windows å¹³å°ä¸‹çš„ asyncio ç­–ç•¥ä¿®å¤
    if sys.platform.lower() == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass  # å·²ç»å¤„ç†è¿‡äº†ï¼Œè¿™é‡Œå¿½ç•¥
